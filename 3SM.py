# -*- coding: utf-8 -*-
"""
Created on Tue Oct 21 13:50:53 2025

@author: ypan1
"""

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import io
from scipy import stats

# è®¾ç½®é¡µé¢
st.set_page_config(
    page_title="ç»Ÿè®¡åˆ†æå·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide"
)

# æ ‡é¢˜å’Œè¯´æ˜
st.title("ğŸ“Š ç»Ÿè®¡åˆ†æå·¥å…·")
st.markdown("""
æä¾›å¤šç§ç¨³å¥ç»Ÿè®¡åˆ†ææ–¹æ³•ï¼Œç”¨äºå¤„ç†åŒ…å«å¼‚å¸¸å€¼çš„æ•°æ®é›†ã€‚
æ”¯æŒè¿­ä»£ç¨³å¥ç»Ÿè®¡æ³•ã€å››åˆ†ä½ç¨³å¥ç»Ÿè®¡æ³•å’ŒQ/Hampelæ³•ã€‚
""")

# ä¾§è¾¹æ  - å‚æ•°è®¾ç½®å’Œæ–¹æ³•é€‰æ‹©
st.sidebar.header("âš™ï¸ åˆ†æè®¾ç½®")

# æ–¹æ³•é€‰æ‹©
method = st.sidebar.selectbox(
    "é€‰æ‹©ç»Ÿè®¡æ–¹æ³•:",
    ["è¿­ä»£ç¨³å¥ç»Ÿè®¡æ³•", "å››åˆ†ä½ç¨³å¥ç»Ÿè®¡æ³•", "Q/Hampelæ³•"],
    help="é€‰æ‹©é€‚åˆæ•°æ®ç‰¹å¾çš„ç¨³å¥ç»Ÿè®¡æ–¹æ³•"
)

# æ ¹æ®é€‰æ‹©çš„æ–¹æ³•æ˜¾ç¤ºç›¸åº”å‚æ•°
if method == "è¿­ä»£ç¨³å¥ç»Ÿè®¡æ³•":
    k_value = st.sidebar.slider("å°ºåº¦å› å­ (k)", 1.0, 3.0, 1.5, 0.1)
    max_iter = st.sidebar.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 10, 100, 50)
elif method == "å››åˆ†ä½ç¨³å¥ç»Ÿè®¡æ³•":
    st.sidebar.info("å››åˆ†ä½æ³•ä½¿ç”¨å›ºå®šå‚æ•°è®¡ç®—")
elif method == "Q/Hampelæ³•":
    st.sidebar.info("Q/Hampelæ³•ä½¿ç”¨æ ‡å‡†å‚æ•°è®¡ç®—")

# æ•°æ®è¾“å…¥æ–¹å¼é€‰æ‹©
input_method = st.radio("æ•°æ®è¾“å…¥æ–¹å¼:", 
                       ["æ‰‹åŠ¨è¾“å…¥", "æ–‡ä»¶ä¸Šä¼ ", "ç¤ºä¾‹æ•°æ®"])

data = None

if input_method == "æ‰‹åŠ¨è¾“å…¥":
    st.subheader("ğŸ“ æ‰‹åŠ¨è¾“å…¥æ•°æ®")
    data_input = st.text_area("è¯·è¾“å…¥æ•°æ®ï¼ˆæ¯è¡Œä¸€ä¸ªæ•°å€¼æˆ–ç”¨é€—å·åˆ†éš”ï¼‰:", 
                             "54.4, 54.6, 54.2, 54.3, 53.9, 54.4, 54.3, 54.6, 54.5, 54.3, 54.5, 54.1, 54.2, 54.3, 54.8, 54.8, 54.8, 54.3, 54.4, 54.3, 54.3, 54.7, 54.4, 54.5, 54.4, 55.0, 55.0, 55.1, 54.1, 54.8, 54.5, 55.5, 55.6, 55.0, 54.3, 55.3, 54.3, 54.4, 54.3, 54.4, 54.5, 55.9, 53.2, 54.6")
    
    if st.button("åˆ†ææ•°æ®"):
        try:
            # è§£æè¾“å…¥æ•°æ®
            if "\n" in data_input:
                data_list = [float(x.strip()) for x in data_input.split("\n") if x.strip()]
            else:
                data_list = [float(x.strip()) for x in data_input.split(",") if x.strip()]
            
            data = np.array(data_list)
            st.success(f"æˆåŠŸè§£æ {len(data)} ä¸ªæ•°æ®ç‚¹")
            
        except ValueError as e:
            st.error("æ•°æ®æ ¼å¼é”™è¯¯ï¼è¯·ç¡®ä¿è¾“å…¥çš„æ˜¯æ•°å­—")

elif input_method == "æ–‡ä»¶ä¸Šä¼ ":
    st.subheader("ğŸ“ ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    uploaded_file = st.file_uploader("é€‰æ‹©CSVæˆ–TXTæ–‡ä»¶", type=['csv', 'txt'])
    
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
                # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯æ•°æ®
                data = df.iloc[:, 0].values
            else:
                # æ–‡æœ¬æ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªæ•°å­—
                content = uploaded_file.read().decode()
                data_list = [float(x.strip()) for x in content.split() if x.strip()]
                data = np.array(data_list)
            
            st.success(f"æˆåŠŸåŠ è½½ {len(data)} ä¸ªæ•°æ®ç‚¹")
            st.write("å‰10ä¸ªæ•°æ®:", data[:10])
            
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}")

else:  # ç¤ºä¾‹æ•°æ®
    st.subheader("ğŸ¯ ç¤ºä¾‹æ•°æ®åˆ†æ")
    example_data = np.array([
        54.4, 54.6, 54.2, 54.3, 53.9, 54.4, 54.3, 54.6, 54.5, 54.3, 
        54.5, 54.1, 54.2, 54.3, 54.8, 54.8, 54.8, 54.3, 54.4, 54.3, 
        54.3, 54.7, 54.4, 54.5, 54.4, 55.0, 55.0, 55.1, 54.1, 54.8, 
        54.5, 55.5, 55.6, 55.0, 54.3, 55.3, 54.3, 54.4, 54.3, 54.4, 
        54.5, 55.9, 53.2, 54.6
    ])
    data = example_data
    st.write("ç¤ºä¾‹æ•°æ®å·²åŠ è½½ï¼ŒåŒ…å«44ä¸ªæµ‹é‡å€¼")

# æ–¹æ³•æè¿°
st.sidebar.header("ğŸ“š æ–¹æ³•è¯´æ˜")
if method == "è¿­ä»£ç¨³å¥ç»Ÿè®¡æ³•":
    st.sidebar.info("""
    **è¿­ä»£ç¨³å¥ç»Ÿè®¡æ³•**ï¼ˆç®—æ³•Aï¼‰é€šè¿‡è¿­ä»£è¿‡ç¨‹é€æ­¥ä¿®æ­£å¼‚å¸¸å€¼å½±å“ï¼Œ
    æ”¶æ•›åå¾—åˆ°ç¨³å¥çš„ç»Ÿè®¡ä¼°è®¡ã€‚
    """)
elif method == "å››åˆ†ä½ç¨³å¥ç»Ÿè®¡æ³•":
    st.sidebar.info("""
    **å››åˆ†ä½ç¨³å¥ç»Ÿè®¡æ³•**ä»¥æ•°æ®æ’åºä¸ºåŸºç¡€ï¼Œä½¿ç”¨æ•°æ®é›†ä¸­æ®µ50%çš„æ•°æ®ï¼Œ
    å´©æºƒç‚¹ä¸º25%ï¼Œå…·æœ‰æ˜“äºè®¡ç®—ã€æ“ä½œç®€å•çš„ç‰¹ç‚¹ã€‚
    """)
else:  # Q/Hampelæ³•
    st.sidebar.info("""
    **Q/Hampelæ³•**ç»“åˆQæ–¹æ³•è®¡ç®—çš„ç¨³å¥æ ‡å‡†å·®å’ŒHampelæ–¹æ³•è®¡ç®—çš„
    ç¨³å¥å¹³å‡å€¼ï¼Œå…·æœ‰è¾ƒå¥½çš„æŠ—å¼‚å¸¸å€¼å¹²æ‰°èƒ½åŠ›ã€‚
    """)

# ç»Ÿè®¡æ–¹æ³•å®ç°
def iterative_robust_algorithm(data, max_iterations=50, k=1.5):
    """
    è¿­ä»£ç¨³å¥ç»Ÿè®¡æ³•ï¼ˆåŸç®—æ³•Aï¼‰
    """
    n = len(data)
    
    # åˆå§‹å€¼
    X_star = np.median(data)
    abs_deviations = np.abs(data - X_star)
    median_abs_deviation = np.median(abs_deviations)
    S_star = 1.483 * median_abs_deviation
    
    # è¿­ä»£è¿‡ç¨‹
    converged = False
    iteration = 0
    history = []
    
    while iteration < max_iterations and not converged:
        iteration += 1
        prev_X_star = X_star
        prev_S_star = S_star
        
        # è®¡ç®—Î´å¹¶ä¿®æ­£æ•°æ®ç‚¹
        delta = k * S_star
        Xj_star = np.where(data < X_star - delta, X_star - delta, 
                          np.where(data > X_star + delta, X_star + delta, data))
        
        # é‡æ–°è®¡ç®—
        X_star = np.mean(Xj_star)
        sum_squared_deviations = np.sum((Xj_star - X_star)**2)
        S_star = 1.134 * np.sqrt(sum_squared_deviations / (n-1))
        
        # è®°å½•å†å²
        history.append({
            'iteration': iteration,
            'X_star': X_star,
            'S_star': S_star,
            'delta': delta
        })
        
        # æ£€æŸ¥æ”¶æ•›
        if (int(prev_X_star * 1000) == int(X_star * 1000) and 
            int(prev_S_star * 1000) == int(S_star * 1000)):
            converged = True
    
    # æœ€ç»ˆç»“æœ
    final_delta = k * S_star
    lower_limit = X_star - final_delta
    upper_limit = X_star + final_delta
    outliers_mask = (data < lower_limit) | (data > upper_limit)
    outliers = data[outliers_mask]
    clean_data = data[~outliers_mask]
    Z_scores = (data - X_star) / S_star
    
    return {
        'robust_mean': X_star,
        'robust_std': S_star,
        'clean_data': clean_data,
        'outliers': outliers,
        'Z_scores': Z_scores,
        'iterations': iteration,
        'converged': converged,
        'lower_limit': lower_limit,
        'upper_limit': upper_limit,
        'history': history,
        'method_name': 'è¿­ä»£ç¨³å¥ç»Ÿè®¡æ³•'
    }

def quartile_robust_algorithm(data):
    """
    å››åˆ†ä½ç¨³å¥ç»Ÿè®¡æ³•
    """
    # æ•°æ®æ’åº
    sorted_data = np.sort(data)
    n = len(sorted_data)
    
    # è®¡ç®—ä¸­ä½å€¼
    if n % 2 == 1:
        median = sorted_data[n // 2]
    else:
        median = (sorted_data[n // 2 - 1] + sorted_data[n // 2]) / 2
    
    # è®¡ç®—å››åˆ†ä½æ•°
    q1 = np.percentile(data, 25)  # ä¸‹å››åˆ†ä½æ•°
    q3 = np.percentile(data, 75)  # ä¸Šå››åˆ†ä½æ•°
    
    # è®¡ç®—å››åˆ†ä½è·å’Œæ ‡å‡†åŒ–å››åˆ†ä½è·
    iqr = q3 - q1
    niqr = 0.7413 * iqr  # æ ‡å‡†åŒ–å››åˆ†ä½è·
    
    # è®¡ç®—æ­£å¸¸å€¼èŒƒå›´ï¼ˆåŸºäºå››åˆ†ä½æ•°ï¼‰
    lower_limit = q1 - 1.5 * iqr
    upper_limit = q3 + 1.5 * iqr
    
    # è¯†åˆ«ç¦»ç¾¤å€¼
    outliers_mask = (data < lower_limit) | (data > upper_limit)
    outliers = data[outliers_mask]
    clean_data = data[~outliers_mask]
    
    # è®¡ç®—Zæ¯”åˆ†æ•°ï¼ˆä½¿ç”¨ä¸­ä½å€¼å’ŒNIQRï¼‰
    Z_scores = (data - median) / niqr
    
    return {
        'robust_mean': median,      # ä½¿ç”¨ä¸­ä½å€¼ä½œä¸ºç¨³å¥å¹³å‡å€¼
        'robust_std': niqr,         # ä½¿ç”¨NIQRä½œä¸ºç¨³å¥æ ‡å‡†å·®
        'clean_data': clean_data,
        'outliers': outliers,
        'Z_scores': Z_scores,
        'q1': q1,
        'q3': q3,
        'iqr': iqr,
        'niqr': niqr,
        'method_name': 'å››åˆ†ä½ç¨³å¥ç»Ÿè®¡æ³•',
        'lower_limit': lower_limit,
        'upper_limit': upper_limit
    }

def q_hampel_robust_algorithm(data):
    """
    Q/Hampelç¨³å¥ç»Ÿè®¡æ–¹æ³•
    """
    # ç®€åŒ–ç‰ˆçš„Q/Hampelå®ç°
    # æ³¨æ„ï¼šå®Œæ•´çš„Q/Hampelæ–¹æ³•éœ€è¦å¤šä¸ªå®éªŒå®¤æ•°æ®ï¼Œè¿™é‡Œæä¾›ç®€åŒ–ç‰ˆæœ¬
    
    n = len(data)
    
    # è®¡ç®—ä¸­ä½å€¼ï¼ˆä½œä¸ºHampelæ–¹æ³•çš„åˆå§‹ä¼°è®¡ï¼‰
    median = np.median(data)
    
    # è®¡ç®—Qæ–¹æ³•çš„ç¨³å¥æ ‡å‡†å·®ï¼ˆç®€åŒ–ç‰ˆï¼‰
    # åŸºäºæˆå¯¹ç»å¯¹å·®çš„ä¸­ä½æ•°
    pairs = []
    for i in range(n):
        for j in range(i+1, n):
            pairs.append(abs(data[i] - data[j]))
    
    if len(pairs) > 0:
        q_std = np.median(pairs) / 1.0484  # è°ƒæ•´ç³»æ•°
    else:
        q_std = np.std(data, ddof=1)
    
    # Hampelæ–¹æ³•çš„ç¨³å¥å¹³å‡å€¼ï¼ˆè¿­ä»£åŠ æƒæ³•ç®€åŒ–ç‰ˆï¼‰
    # ä½¿ç”¨ä¸­ä½å€¼ä½œä¸ºåˆå§‹ä¼°è®¡
    current_mean = median
    max_iterations = 10
    tolerance = 1e-6
    
    for iteration in range(max_iterations):
        # è®¡ç®—æ®‹å·®
        residuals = data - current_mean
        mad = np.median(np.abs(residuals))
        
        if mad == 0:
            break
            
        # æ ‡å‡†åŒ–æ®‹å·®
        standardized_residuals = residuals / (1.4826 * mad)
        
        # Hampelæƒé‡å‡½æ•°
        weights = np.ones_like(data)
        mask1 = np.abs(standardized_residuals) > 1.5
        mask2 = np.abs(standardized_residuals) > 3
        mask3 = np.abs(standardized_residuals) > 4.5
        
        weights[mask1] = 1.5 / np.abs(standardized_residuals[mask1])
        weights[mask2] = 0
        weights[mask3] = 0
        
        # æ›´æ–°å‡å€¼
        new_mean = np.sum(weights * data) / np.sum(weights)
        
        # æ£€æŸ¥æ”¶æ•›
        if abs(new_mean - current_mean) < tolerance:
            break
            
        current_mean = new_mean
    
    # è®¡ç®—æ­£å¸¸å€¼èŒƒå›´
    lower_limit = current_mean - 3 * q_std
    upper_limit = current_mean + 3 * q_std
    
    # è¯†åˆ«ç¦»ç¾¤å€¼
    outliers_mask = (data < lower_limit) | (data > upper_limit)
    outliers = data[outliers_mask]
    clean_data = data[~outliers_mask]
    
    # è®¡ç®—Zæ¯”åˆ†æ•°
    Z_scores = (data - current_mean) / q_std
    
    return {
        'robust_mean': current_mean,  # Hampelç¨³å¥å¹³å‡å€¼
        'robust_std': q_std,          # Qæ–¹æ³•ç¨³å¥æ ‡å‡†å·®
        'clean_data': clean_data,
        'outliers': outliers,
        'Z_scores': Z_scores,
        'method_name': 'Q/Hampelæ³•',
        'lower_limit': lower_limit,
        'upper_limit': upper_limit,
        'weights': weights if 'weights' in locals() else np.ones_like(data)
    }

# æ‰§è¡Œåˆ†æ
if data is not None and len(data) > 0:
    st.markdown("---")
    st.subheader(f"ğŸ“ˆ {method}åˆ†æç»“æœ")
    
    with st.spinner(f"æ­£åœ¨æ‰§è¡Œ{method}åˆ†æ..."):
        if method == "è¿­ä»£ç¨³å¥ç»Ÿè®¡æ³•":
            results = iterative_robust_algorithm(data, max_iterations=max_iter, k=k_value)
        elif method == "å››åˆ†ä½ç¨³å¥ç»Ÿè®¡æ³•":
            results = quartile_robust_algorithm(data)
        else:  # Q/Hampelæ³•
            results = q_hampel_robust_algorithm(data)
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("ç¨³å¥å¹³å‡å€¼", f"{results['robust_mean']:.6f}")
        st.metric("ç¨³å¥æ ‡å‡†å·®", f"{results['robust_std']:.6f}")
        
    with col2:
        if 'iterations' in results:
            st.metric("è¿­ä»£æ¬¡æ•°", results['iterations'])
        st.metric("ç¦»ç¾¤å€¼æ•°é‡", len(results['outliers']))
    
    # æ–¹æ³•ç‰¹å®šç»“æœæ˜¾ç¤º
    if method == "å››åˆ†ä½ç¨³å¥ç»Ÿè®¡æ³•":
        st.info("ğŸ“Š **å››åˆ†ä½ç»Ÿè®¡é‡:**")
        col3, col4, col5, col6 = st.columns(4)
        with col3:
            st.metric("ä¸‹å››åˆ†ä½æ•°(Q1)", f"{results['q1']:.6f}")
        with col4:
            st.metric("ä¸Šå››åˆ†ä½æ•°(Q3)", f"{results['q3']:.6f}")
        with col5:
            st.metric("å››åˆ†ä½è·(IQR)", f"{results['iqr']:.6f}")
        with col6:
            st.metric("æ ‡å‡†åŒ–å››åˆ†ä½è·(NIQR)", f"{results['niqr']:.6f}")
    
    # è¯¦ç»†ç»“æœ
    st.subheader("ğŸ“‹ è¯¦ç»†ç»“æœ")
    
    st.write(f"**æ­£å¸¸å€¼èŒƒå›´**: [{results['lower_limit']:.6f}, {results['upper_limit']:.6f}]")
    if 'converged' in results:
        st.write(f"**æ”¶æ•›çŠ¶æ€**: {'æ˜¯' if results['converged'] else 'å¦'}")
    
    if len(results['outliers']) > 0:
        # å°†np.float64è½¬æ¢ä¸ºPythonåŸç”Ÿfloatç±»å‹
        outliers_list = [float(x) for x in sorted(results['outliers'])]
        st.write(f"**ç¦»ç¾¤å€¼**: {outliers_list}")
    else:
        st.write("**ç¦»ç¾¤å€¼**: æ— ")
    
    # Zæ¯”åˆ†æ•°ç»Ÿè®¡
    z_scores_abs = np.abs(results['Z_scores'])
    satisfactory = np.sum(z_scores_abs <= 2)
    questionable = np.sum((z_scores_abs > 2) & (z_scores_abs <= 3))
    unsatisfactory = np.sum(z_scores_abs > 3)
    
    st.write("**Zæ¯”åˆ†æ•°åˆ†ç±»**:")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ»¡æ„ (|Z| â‰¤ 2)", f"{satisfactory} ä¸ª")
    with col2:
        st.metric("å¯ç–‘ (2 < |Z| â‰¤ 3)", f"{questionable} ä¸ª")
    with col3:
        st.metric("ä¸æ»¡æ„ (|Z| > 3)", f"{unsatisfactory} ä¸ª")
    
    # å¯è§†åŒ– - ä½¿ç”¨æ–°çš„Zå€¼æŸ±çŠ¶å›¾
    st.subheader("ğŸ“Š Data Visualization")

   # åˆ›å»ºæ•°æ®æ¡†ç”¨äºå¯è§†åŒ–
    df_clean = pd.DataFrame({
        'Original_Data': data,
        'Z_Score': results['Z_scores']  # ç¡®ä¿åˆ—åä¸€è‡´
})

    # æ ¹æ®Zå€¼è¿›è¡Œåˆ†ç±»
    def classify_data(row):
        if abs(row['Z_Score']) <= 2:
            return 'Satisfactory'
        elif 2 < abs(row['Z_Score']) <= 3:
            return 'Questionable'
        else:
            return 'Unsatisfactory'

    df_clean['Category'] = df_clean.apply(classify_data, axis=1)

    # ç¡®ä¿åˆ—åæ­£ç¡®ï¼Œç„¶åæŒ‰ç…§Zå€¼ä»å¤§åˆ°å°æ’åº
    # é¦–å…ˆæ£€æŸ¥åˆ—åæ˜¯å¦å­˜åœ¨
    if 'Z_Score' in df_clean.columns:
        df_sorted = df_clean.sort_values('Z_Score', ascending=False)
    else:
    # å¦‚æœåˆ—åä¸æ˜¯ 'Z_Score'ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„åˆ—å
        st.error(f"åˆ—å 'Z_Score' ä¸å­˜åœ¨ã€‚å¯ç”¨çš„åˆ—å: {list(df_clean.columns)}")
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°å€¼åˆ—è¿›è¡Œæ’åº
        numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            df_sorted = df_clean.sort_values(numeric_cols[0], ascending=False)
        else:
            df_sorted = df_clean

    # åˆ›å»ºZå€¼æŸ±çŠ¶å›¾
    fig, ax = plt.subplots(figsize=(14, 10))

    # è®¾ç½®ç±»åˆ«å¯¹åº”çš„é¢œè‰²
    color_map = {
        'Satisfactory': '#2E8B57',    # ç»¿è‰²
        'Questionable': '#FFA500',    # æ©™è‰²
        'Unsatisfactory': '#DC143C'    # çº¢è‰²
    }

    # ä¸ºæ¯ä¸ªç±»åˆ«åˆ›å»ºæŸ±çŠ¶å›¾
    for category, color in color_map.items():
        category_data = df_sorted[df_sorted['Category'] == category]
        if not category_data.empty:
        # ä½¿ç”¨æ’åºåçš„ç´¢å¼•ä½œä¸ºYè½´æ ‡ç­¾
            bars = ax.barh([str(idx) for idx in category_data.index], 
                      category_data['Z_Score'], 
                      color=color, alpha=0.7, label=category, height=0.8)
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ ‡æ³¨Zå€¼
            for bar, z_value in zip(bars, category_data['Z_Score']):
                plt.text(bar.get_width() + 0.05 * (1 if bar.get_width() >= 0 else -1), 
                    bar.get_y() + bar.get_height()/2, 
                    f'{z_value:.2f}', 
                    ha='left' if bar.get_width() >= 0 else 'right', 
                    va='center', fontsize=9, fontweight='bold')

    # è®¾ç½®å›¾å½¢å±æ€§
    ax.set_xlabel('Z-Score', fontsize=14, fontweight='bold')
    ax.set_ylabel('Data ID (Sorted by Z-Score)', fontsize=14, fontweight='bold')
    ax.set_title(f'{method} - Z-Score Distribution (Sorted)', fontsize=16, fontweight='bold')

    # æ·»åŠ é›¶çº¿å‚è€ƒçº¿
    ax.axvline(x=0, color='black', linestyle='-', alpha=0.5, linewidth=1)

    # æ·»åŠ é˜ˆå€¼çº¿
    ax.axvline(x=-2, color='gray', linestyle='--', alpha=0.7, linewidth=0.8)
    ax.axvline(x=2, color='gray', linestyle='--', alpha=0.7, linewidth=0.8)
    ax.axvline(x=-3, color='red', linestyle='--', alpha=0.7, linewidth=0.8)
    ax.axvline(x=3, color='red', linestyle='--', alpha=0.7, linewidth=0.8)

    # æ·»åŠ ç½‘æ ¼
    ax.grid(axis='x', alpha=0.3, linestyle='--')

    # æ·»åŠ å›¾ä¾‹
    ax.legend(title='Category', title_fontsize=12, fontsize=11, loc='upper right')

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()

    # æ˜¾ç¤ºå›¾è¡¨
    st.pyplot(fig)
    
    # å¯¼å‡ºåŠŸèƒ½
    st.subheader("ğŸ’¾ å¯¼å‡ºç»“æœ")
    
    # åˆ›å»ºç»“æœDataFrame
    result_df = pd.DataFrame({
        'åŸå§‹æ•°æ®': data,
        'Zæ¯”åˆ†æ•°': results['Z_scores'],
        'åˆ†ç±»': np.where(np.abs(results['Z_scores']) <= 2, 'æ»¡æ„',
                       np.where(np.abs(results['Z_scores']) <= 3, 'å¯ç–‘', 'ä¸æ»¡æ„'))
    })
    
    # ä¸‹è½½CSV
    csv = result_df.to_csv(index=False)
    st.download_button(
        label="ä¸‹è½½å®Œæ•´ç»“æœCSV",
        data=csv,
        file_name=f"{method}_åˆ†æç»“æœ.csv",
        mime="text/csv"
    )
    
    # ä¸‹è½½æŠ¥å‘Š
    report = f"""
{method}åˆ†ææŠ¥å‘Š
================

åˆ†ææ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
æ•°æ®ç‚¹æ•°: {len(data)}
ä½¿ç”¨æ–¹æ³•: {method}

å…³é”®ç»“æœ:
--------
ç¨³å¥å¹³å‡å€¼: {results['robust_mean']:.6f}
ç¨³å¥æ ‡å‡†å·®: {results['robust_std']:.6f}
æ­£å¸¸å€¼èŒƒå›´: [{results['lower_limit']:.6f}, {results['upper_limit']:.6f}]
ç¦»ç¾¤å€¼æ•°é‡: {len(results['outliers'])}

"""
    
    if method == "å››åˆ†ä½ç¨³å¥ç»Ÿè®¡æ³•":
        report += f"""
å››åˆ†ä½ç»Ÿè®¡é‡:
-----------
ä¸‹å››åˆ†ä½æ•°(Q1): {results['q1']:.6f}
ä¸Šå››åˆ†ä½æ•°(Q3): {results['q3']:.6f}
å››åˆ†ä½è·(IQR): {results['iqr']:.6f}
æ ‡å‡†åŒ–å››åˆ†ä½è·(NIQR): {results['niqr']:.6f}

"""
    
    if 'iterations' in results:
        report += f"è¿­ä»£æ¬¡æ•°: {results['iterations']}\n"
    
    report += f"""
æ•°æ®è´¨é‡åˆ†ç±»:
-----------
æ»¡æ„ (|Z| â‰¤ 2): {satisfactory} ä¸ªæ•°æ®ç‚¹
å¯ç–‘ (2 < |Z| â‰¤ 3): {questionable} ä¸ªæ•°æ®ç‚¹  
ä¸æ»¡æ„ (|Z| > 3): {unsatisfactory} ä¸ªæ•°æ®ç‚¹

ç¦»ç¾¤å€¼åˆ—è¡¨:
----------
{', '.join([str(float(x)) for x in results['outliers']])}
"""
    
    st.download_button(
        label="ä¸‹è½½åˆ†ææŠ¥å‘Š",
        data=report,
        file_name=f"{method}_åˆ†ææŠ¥å‘Š.txt",
        mime="text/plain"
    )

else:
    st.info("ğŸ‘† è¯·å…ˆè¾“å…¥æˆ–ä¸Šä¼ æ•°æ®ä»¥å¼€å§‹åˆ†æ")

# é¡µè„š
st.markdown("---")
st.markdown("""
**æ–¹æ³•è¯´æ˜:**
- **è¿­ä»£ç¨³å¥ç»Ÿè®¡æ³•**: é€šè¿‡è¿­ä»£è¿‡ç¨‹é€æ­¥ä¿®æ­£å¼‚å¸¸å€¼å½±å“
- **å››åˆ†ä½ç¨³å¥ç»Ÿè®¡æ³•**: åŸºäºæ•°æ®æ’åºï¼Œä½¿ç”¨ä¸­æ®µ50%æ•°æ®ï¼Œå´©æºƒç‚¹25%
- **Q/Hampelæ³•**: ç»“åˆQæ–¹æ³•ç¨³å¥æ ‡å‡†å·®å’ŒHampelæ–¹æ³•ç¨³å¥å¹³å‡å€¼
""")